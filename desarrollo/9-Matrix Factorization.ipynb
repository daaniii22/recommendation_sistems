{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjPUbFbgwPhR"
   },
   "source": [
    "# Filtrado Colaborativo: *Probabilistic Matrix Factorization*\n",
    "\n",
    "Durante los inicios del filtrado colaborativo el algoritmo de KNN era el más empleado debido a los buenos resultados que reportaba y a la facilidad con la que podían explicarse sus recomendaciones. Sin embargo, este algoritmo tiene una gran desventaja: su escalabilidad. El algoritmo de KNN funciona bien para datasets de tamaño medio, pero, a medida que el dataset crece, los tiempos de cómputo para obtener las recomendaciones se vuelven inasumibles. Aumentar el número de usuarios y/o el número de items implica ralentizar el cálculo de las similaridades, la búsqueda de los k vecinos y el número de predicciones a realizar.\n",
    "\n",
    "Como consecuencia de estos problemas y del gran empuje que supuso el [Netflix Prize](https://www.netflixprize.com/) (concurso que ofrecía una recompensa de 1M de dólares al equipo que consiguiera mejorar el RMSE en el dataset de Netflix) comenzaron a ganar fuerza los sistemas de filtrado colaborativo basados en modelos, más concretamente los basados en modelos de factorización matricial.\n",
    "\n",
    "El **filtrado colaborativo basado en factorización matricial** se basa en la siguiente idea: las votaciones que los usuarios realizan a los items están condicionadas por una serie de factores latentes intrínsecos a los usuarios y los items. Ilustremos esto con un ejemplo. Supongamos un sistema de recomendación de películas. Lo que postula la factorización matricial es que los usuarios votan las películas basándose no sólo en la propia película, sino que lo hacen basándose en las características que describen esa película. Si a un usuario le gustan las películas de acción con un toque de comedia, es muy probable que le gusten todas las películas de acción con un toque de comedia. Los algoritmos de filtrado colaborativo buscan estas propiedades intrínsecas al dominio en el que se realizan las recomendaciones y las denominan **factores latentes** u ocultos. Es importante resaltar que estos factores son ocultos, y aunque en el ejemplo de la recomendación de películas podamos suponer que se trata de géneros de cine, el modelo nunca nos va a indicar con qué género se corresponde cada factor.\n",
    "\n",
    "Matemáticamente, la factorización matricial consiste en encontrar las matrices $P$ y $Q$ que satisfagan la siguiente expresión:\n",
    "\n",
    "$$R \\approx P \\cdot Q$$\n",
    "\n",
    "En esta expresión:\n",
    "\n",
    "- $R$ representa la matriz (dispersa) con las votaciones de los usuarios (filas) a los items (columnas).\n",
    "- $P$ representa las matriz (densa) de factores de los usuarios (filas) con los *k* factores latentes (columnas).\n",
    "- $Q$ representa las matriz (densa) de factores de los items (columnas) con los *k* factores latentes (filas).\n",
    "\n",
    "Como vemos, los modelos tienen un parámetro que será necesario tunear con el fin de ajustar el modelo a cada dataset. Este parámetro ***k*** representa el número de factores latentes de nuestro modelo.\n",
    "\n",
    "Desarrollando la expresión anterior, podemos inferir que la predicción de voto de un usuario $u$ a un item $i$ queda como:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\vec{p}_u \\cdot \\vec{q}_i$$\n",
    "\n",
    "Dónde $\\vec{p}_u$ representa un vector fila de la matriz $P$ con los factores latentes del usuario $u$ y $\\vec{q}_i$ representa un vector columna de la matriz $Q$ con los factores latentes del item $i$.\n",
    "\n",
    "Por lo tanto, podemos plantear la búsqueda de los factores latentes como un problema de optimización, en el cual buscamos minimizar el error cometido en los votos conocidos:\n",
    "\n",
    "$$\\min_{p,q} \\sum_{(u,i) \\in R} ( r_{u,i} - \\vec{p}_u \\cdot \\vec{q}_i)^2$$\n",
    "\n",
    "Expresión a la que podemos añadir una regularización para evitar el *overfitting*:\n",
    "\n",
    "$$\\min_{p,q} \\sum_{(u,i) \\in R} ( r_{u,i} - \\vec{p}_u \\cdot \\vec{q}_i)^2 + \\lambda (||\\vec{p}_u||^2 + ||\\vec{q}_i||^2)$$\n",
    "\n",
    "Es posible resolver este problema mediante la técnica de descenso de gradiente, para lo cual debemos encontrar la derivada de la expresión anterior respecto del $\\vec{p}_u$ y $\\vec{q}_i$.\n",
    "\n",
    "Una vez entrenado el modelo, las matrices $P$ y $Q$ son aprendidas y no necesitan modificarse hasta que la matriz de votaciones cambie sustancialmente. Obtener una predicción una vez el modelo ha aprendido implica, simplemente, realizar el producto escalar de dos vectores de dimensión *k*, que, por lo general, suele ser un valor pequeño.\n",
    "\n",
    "A este algoritmo se le conoce como ***Probabilistic Matriz Factorization (PMF)***.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj19DL6RCIZq"
   },
   "source": [
    "## Carga del dataset\n",
    "\n",
    "Para ilustar mejor el funcionamiento del algoritmo PMF, vamos a desarrollar una implementación del mismo.\n",
    "\n",
    "Para ello usaremos el dataset de [MovieLens 100K](https://grouplens.org/datasets/movielens/) que contiene 100.000 votos de 943 usuarios sobre 1682 películas. Este dataset ha sido dividido en votaciones de entrenamiento (80%) y votaciones de test (20%). Además, los códigos de usuarios e items, han sido modificados para que comience en 0 y terminen en el número de (usuarios / items) - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Y1rRJ8hCi2A"
   },
   "source": [
    "Inicialmente definimos algunas constantes que nos serán necesarias durante la codificación del algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j-n03OB1CxVe"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f6WGa59gwPhS"
   },
   "outputs": [],
   "source": [
    "NUM_USERS = 943\n",
    "NUM_ITEMS = 1682\n",
    "\n",
    "MIN_RATING = 1\n",
    "MAX_RATING = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYYRgNNZtGpE"
   },
   "source": [
    "Y cargamos la matriz con las votaciones de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aGtDGaQEwPhW"
   },
   "outputs": [],
   "source": [
    "ratings = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)]\n",
    "\n",
    "training_file = urllib.request.urlopen(\"https://drive.upm.es/s/tDdluElfGInyUnU/download\")\n",
    "for line in training_file:\n",
    "  [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n",
    "  ratings[int(u)][int(i)] = int(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_np = np.array(ratings)\n",
    "ratings_np[ratings_np == None] = np.nan\n",
    "ratings_np = ratings_np.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynbsIDxnC2OI"
   },
   "source": [
    "Del mismo modo, cargamos la matriz de votaciones de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qJ4y0dY8C5GB"
   },
   "outputs": [],
   "source": [
    "test_ratings = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)]\n",
    "\n",
    "test_file = urllib.request.urlopen(\"https://drive.upm.es/s/Jn75Vg6okOPsgZu/download\")\n",
    "for line in test_file:\n",
    "  [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n",
    "  test_ratings[int(u)][int(i)] = int(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings_np = np.array(test_ratings)\n",
    "test_ratings_np[test_ratings_np == None] = np.nan\n",
    "test_ratings_np = test_ratings_np.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJ_HI4_pwPhZ"
   },
   "source": [
    "## Inicialización del modelo\n",
    "\n",
    "Definimos los parámetros necesarios para implementar la factorización matricial mediante PMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OLkqFAFgwPha"
   },
   "outputs": [],
   "source": [
    "NUM_FACTORS = 7\n",
    "LEARNING_RATE = 0.001 # gamma\n",
    "REGULARIZATION = 0.1 # lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6LFYsvgwPhd"
   },
   "source": [
    "Inicializamos las matrices de factores con valores uniformes aleatorios en el intervalo \\[0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GiMfSEhZwPhe"
   },
   "outputs": [],
   "source": [
    "p = [[random.random() for _ in range(NUM_FACTORS)] for _ in range(NUM_USERS)]\n",
    "q = [[random.random() for _ in range(NUM_FACTORS)] for _ in range(NUM_ITEMS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_np = np.array(p) #np.random.random((NUM_USERS, NUM_FACTORS))\n",
    "q_np = np.array(q) #np.random.random((NUM_ITEMS, NUM_FACTORS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCTcKsnewPhg"
   },
   "source": [
    "## Cálculo de las predicciones\n",
    "\n",
    "Como hemos comentado, calcular la predicción del voto del usuario *u* al item *i* implicar realizar el producto escalar de sus vectores de factores. La siguiente función realiza esta operación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction_old(p_u, q_i):\n",
    "    # prediction = 0\n",
    "    # for k in range(NUM_FACTORS):\n",
    "    #     prediction += p_u[k] * q_i[k]\n",
    "    return sum(p_u[k] * q_i[k] for k in range(NUM_FACTORS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3245684876076944"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_prediction_old(p[0], q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction(p_u, q_i):\n",
    "    return np.dot(p_u, q_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915 ns ± 81.2 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "924 ns ± 19 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "838 ns ± 29 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Al ser pocos factores vamos a tener que tener cuidado al vectorizar porque \n",
    "# podemos acabar haciéndolo más lento que con python nativo\n",
    "%timeit -n 100_000 compute_prediction_old(p[0], q[0])\n",
    "%timeit -n 100_000 compute_prediction_old(p[0], q[0])\n",
    "%timeit -n 100_000 compute_prediction(p_np[0], q_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3424906359092708"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_prediction(p_np[0], q_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQAGR9VWHCVe"
   },
   "source": [
    "## Aprendizaje de los factores latentes\n",
    "\n",
    "El proceso de entrenamiento implicar aplicar las operaciones de actualización de las matrices de factores hasta que el algoritmo converja. En general, esta convergencia suele prefijarse como el número de iteraciones que realizamos sobre las operaciones de actualización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XSqfmucPHY0g"
   },
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCNTid22HbDN"
   },
   "source": [
    "Es importante resaltar que sólo debemos actualizar las matrices $P$ y $Q$ empleando los votos existentes en la matriz $R$.\n",
    "\n",
    "El siguiente código ejemplifica el proceso de entrenamiento del algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:04,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 2 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:04,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 3 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:03,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:02<00:03,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 5 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:02<00:02,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 6 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:03<00:02,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 7 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:03<00:01,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 8 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:04<00:01,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 9 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:04<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 10 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for it in tqdm(range(NUM_ITERATIONS)):\n",
    "    print(\"Iteración \" + str(it + 1) + \" de \" + str(NUM_ITERATIONS))\n",
    "\n",
    "    updated_p = list(p) # clone p matrix\n",
    "    updated_q = list(q) # clone q matrix\n",
    "\n",
    "    for u in range(NUM_USERS):\n",
    "        for i in range(NUM_ITEMS):\n",
    "            if ratings[u][i] != None:\n",
    "\n",
    "                prediction = compute_prediction_old(p[u], q[i])\n",
    "                rating = ratings[u][i]\n",
    "                error = rating - prediction\n",
    "\n",
    "                for k in range(NUM_FACTORS):\n",
    "                    updated_p[u][k] += LEARNING_RATE * (error * q[i][k] - REGULARIZATION * p[u][k])\n",
    "                    updated_q[i][k] += LEARNING_RATE * (error * p[u][k] - REGULARIZATION * q[i][k])\n",
    "\n",
    "    p = updated_p\n",
    "    q = updated_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert ratings to a pandas DataFrame with MultiIndex for sparse representation\n",
    "ratings_data = []\n",
    "for u in range(NUM_USERS):\n",
    "    for i in range(NUM_ITEMS):\n",
    "        if ratings[u][i] is not None:\n",
    "            ratings_data.append((u, i, ratings[u][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:20,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 2 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 3 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:15,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 5 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 6 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:13<00:08,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 7 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:15<00:06,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 8 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:17<00:04,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 9 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:19<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 10 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "ratings_df = pd.DataFrame(ratings_data, columns=['user', 'item', 'rating'])\n",
    "ratings_df.set_index(['user', 'item'], inplace=True)\n",
    "\n",
    "for it in tqdm(range(NUM_ITERATIONS)):\n",
    "    print(\"Iteración \" + str(it + 1) + \" de \" + str(NUM_ITERATIONS))\n",
    "\n",
    "    updated_p = list(p)  # clone p matrix\n",
    "    updated_q = list(q)  # clone q matrix\n",
    "\n",
    "    # Iterate through ratings DataFrame instead of nested loops\n",
    "    for (u, i), row in ratings_df.iterrows():\n",
    "        prediction = compute_prediction_old(p[u], q[i])\n",
    "        rating = row['rating']\n",
    "        error = rating - prediction\n",
    "\n",
    "        for k in range(NUM_FACTORS):\n",
    "            updated_p[u][k] += LEARNING_RATE * (error * q[i][k] - REGULARIZATION * p[u][k])\n",
    "            updated_q[i][k] += LEARNING_RATE * (error * p[u][k] - REGULARIZATION * q[i][k])\n",
    "\n",
    "    p = updated_p\n",
    "    q = updated_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:03,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 2 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:03,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 3 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:02,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:01<00:02,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 5 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:01<00:01,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 6 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:02<00:01,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 7 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:02<00:01,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 8 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:03<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 9 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:03<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 10 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.43it/s]\n"
     ]
    }
   ],
   "source": [
    "ratings = np.asarray(ratings)\n",
    "valids = ~np.isnan(ratings_np)\n",
    "valids3D = valids[..., np.newaxis]\n",
    "full_shape = *ratings_np.shape, NUM_FACTORS\n",
    "for it in tqdm(range(NUM_ITERATIONS)):\n",
    "    print(\"Iteración \" + str(it + 1) + \" de \" + str(NUM_ITERATIONS))\n",
    "    \n",
    "    predictions = p_np @ q_np.T\n",
    "    errors = ratings_np - predictions\n",
    "    p_np += LEARNING_RATE * (np.broadcast_to(errors[..., np.newaxis], full_shape) * q_np - REGULARIZATION * p_np[:, np.newaxis, :]).sum(axis=1, where=valids3D)\n",
    "    q_np += LEARNING_RATE * (np.broadcast_to(errors[..., np.newaxis], full_shape) * p_np[:, np.newaxis, :] - REGULARIZATION * q_np[np.newaxis, ...]).sum(axis=0, where=valids3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nDssq0bIPJJ"
   },
   "source": [
    "## Cálculo de las recomendaciones\n",
    "\n",
    "El cálculo de las recomendaciones, por lo general, simplemente implica seleccionar los *N* items con una predicción más alta. Por ejemplo, si quisiéramos recomendar *N = 3* items a un usuario que tuviera las siguientes predicciones:\n",
    "\n",
    "|   \t| i1 \t| i2 \t| i3 \t| i4 \t| i5 \t| i6 \t| i7 \t| i8 \t| i9 \t| i10 \t|\n",
    "|:-:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|-----\t|\n",
    "| u \t|   \t|  2,9 \t|    \t|  4,7 \t|  5,0 \t|    \t|  1,2 \t|    \t|   \t|  3,1 \t|\n",
    "\n",
    "Se le recomendarían a dicho usuario los items *i5*, *i4* e *i10*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "qoKzk91plIM6"
   },
   "outputs": [],
   "source": [
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "yfCV4I6PlJbA"
   },
   "outputs": [],
   "source": [
    "def get_recommendations_old(predictions):\n",
    "    recommendations = [None] * N\n",
    "\n",
    "    for n in range(N):\n",
    "\n",
    "        max_value = 0\n",
    "        item = None\n",
    "\n",
    "        for i, value in enumerate(predictions):\n",
    "            if i not in recommendations and value != None and value > max_value:\n",
    "                max_value = value\n",
    "                item = i\n",
    "\n",
    "        recommendations[n] = item\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(predictions):\n",
    "    # Hay que tomar una decisión entre que devuelva recomendaciones nulas o que \n",
    "    # devuelva un número indeterminado de recomendaciones, opto por la segunda \n",
    "    # por eficiencia\n",
    "    if len(predictions) < N:\n",
    "        # Not enough recommendations\n",
    "        recommendations = np.arange(len(predictions))\n",
    "        recommendations = recommendations[~np.isnan(predictions[recommendations])]\n",
    "        return recommendations\n",
    "    \n",
    "\n",
    "    predictions = np.where(~np.isnan(predictions), predictions, 0)\n",
    "    recommendations = np.argpartition(predictions, -N)[-N:] # Más eficiente que ordenar\n",
    "    return recommendations[predictions[recommendations] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRRAOKWiBKGE"
   },
   "source": [
    "##Ejercicio: Cálculo de Métricas\n",
    "\n",
    "Calcular el error medio absoluto (MAE) y la raiz del error medio cuadrático (RMSE) de las predicciones realizadas por el algoritmo PMF, así como la precisión, recall, F1 y nDCG de las recomendaciones.\n",
    "\n",
    "Para ello, lo primero que debemos hacer es calcular las predicciones para todos los items que haya recibido una votación de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)]\n",
    "\n",
    "# Rellenamos la matriz de predicciones\n",
    "for u in range(NUM_USERS):\n",
    "    for i in range(NUM_ITEMS):\n",
    "        if test_ratings[u][i] != None:\n",
    "            predictions[u][i] = compute_prediction(p[u], q[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "iy1WouoWwzxm"
   },
   "outputs": [],
   "source": [
    "theta = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_mae (u, predictions):\n",
    "  mae = 0\n",
    "  count = 0\n",
    "\n",
    "  for i in range(NUM_ITEMS):\n",
    "    if test_ratings[u][i] != None and predictions[u][i] != None:\n",
    "      mae += abs(test_ratings[u][i] - predictions[u][i])\n",
    "      count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return mae / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae (predictions):\n",
    "  mae = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_mae = get_user_mae(u, predictions)\n",
    "\n",
    "    if user_mae != None:\n",
    "      mae += user_mae\n",
    "      count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return mae / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_user_rmse (u, predictions):\n",
    "  mse = 0\n",
    "  count = 0\n",
    "\n",
    "  for i in range(NUM_ITEMS):\n",
    "    if test_ratings[u][i] != None and predictions[u][i] != None:\n",
    "      mse += (test_ratings[u][i] - predictions[u][i]) * (test_ratings[u][i] - predictions[u][i])\n",
    "      count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return math.sqrt(mse / count)\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse (predictions):\n",
    "  rmse = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_rmse = get_user_rmse(u, predictions)\n",
    "\n",
    "    if user_rmse != None:\n",
    "      rmse += user_rmse\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return rmse / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_precision (u, predictions):\n",
    "  precision = 0\n",
    "  count = 0\n",
    "  recommendations = get_recommendations_old(predictions[u])\n",
    "\n",
    "  for i in recommendations:\n",
    "    if i != None and test_ratings[u][i] != None:\n",
    "      precision += 1 if test_ratings[u][i] >= theta else 0\n",
    "      count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return precision / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision (predictions):\n",
    "  precision = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_precision = get_user_precision(u, predictions)\n",
    "\n",
    "    if user_precision != None:\n",
    "      precision += user_precision\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return precision / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recall (u, predictions):\n",
    "  recall = 0\n",
    "  count = 0\n",
    "  recommendations = get_recommendations_old(predictions[u])\n",
    "\n",
    "  for i in range(NUM_ITEMS):\n",
    "    if test_ratings[u][i] != None and predictions[u][i] != None:\n",
    "      if test_ratings[u][i] >= theta:\n",
    "        recall += 1 if i in recommendations else 0\n",
    "        count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return recall / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall (predictions):\n",
    "  recall = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_recall = get_user_recall(u, predictions)\n",
    "\n",
    "    if user_recall != None:\n",
    "      recall += user_recall\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return recall / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_f1 (u, predictions):\n",
    "  precision = get_user_precision(u, predictions)\n",
    "  recall = get_user_recall(u, predictions)\n",
    "\n",
    "  if precision == None or recall == None:\n",
    "    return None\n",
    "  elif precision == 0 and recall == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1 (predictions):\n",
    "  f1 = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_f1 = get_user_f1(u, predictions)\n",
    "\n",
    "    if user_f1 != None:\n",
    "      f1 += user_f1\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return f1 / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_test_items(u):\n",
    "  num_items = sum(x is not None for x in test_ratings[u])\n",
    "  items = [None for _ in range(num_items)]\n",
    "\n",
    "  for n in range(num_items):\n",
    "\n",
    "    max_value = 0\n",
    "    item = None\n",
    "\n",
    "    for i,value in enumerate(test_ratings[u]):\n",
    "      if i not in items and value != None and value > max_value:\n",
    "        max_value = value\n",
    "        item = i\n",
    "\n",
    "    items[n] = item\n",
    "\n",
    "  return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_idcg (u):\n",
    "  items = get_ordered_test_items(u)\n",
    "  idcg = 0\n",
    "\n",
    "  for pos, i in enumerate(items):\n",
    "    idcg += (2 ** test_ratings[u][i] - 1) / math.log(pos+2, 2)\n",
    "\n",
    "  return idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_dcg (u, recommendations):\n",
    "  dcg = 0\n",
    "\n",
    "  for pos, i in enumerate(recommendations):\n",
    "    if i != None and test_ratings[u][i] != None:\n",
    "      dcg += (2 ** test_ratings[u][i] - 1) / math.log(pos+2, 2)\n",
    "\n",
    "  return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ndcg (u, predictions):\n",
    "  recommendations = get_recommendations_old(predictions[u])\n",
    "  dcg = get_user_dcg(u, recommendations)\n",
    "  idcg = get_user_idcg(u)\n",
    "  if idcg == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg (predictions):\n",
    "  ndcg = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_ndcg = get_user_ndcg(u, predictions)\n",
    "\n",
    "    if user_ndcg != None:\n",
    "      ndcg += user_ndcg\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return ndcg / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.9104854697488575\n",
      "RMSE = 1.0833857192824856\n",
      "Precision = 0.7119658119658115\n",
      "Recall = 0.529894197923319\n",
      "F1 = 0.5275810367587738\n",
      "nDCG = 0.1189806366379144\n"
     ]
    }
   ],
   "source": [
    "mae = get_mae(predictions)\n",
    "rmse = get_rmse(predictions)\n",
    "precision = get_precision(predictions)\n",
    "recall = get_recall(predictions)\n",
    "f1 = get_f1(predictions)\n",
    "ndcg = get_ndcg(predictions)\n",
    "print(\"MAE = \" + str(mae))\n",
    "print(\"RMSE = \" + str(rmse))\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))\n",
    "print(\"F1 = \" + str(f1))\n",
    "print(\"nDCG = \" + str(ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (p_np @ q_np.T).astype(object)\n",
    "predictions[np.isnan(test_ratings_np)] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.8994380838623752\n",
      "RMSE = 1.0648006812175972\n",
      "Precision = 0.7078632478632474\n",
      "Recall = 0.528925545768728\n",
      "F1 = 0.5247101037151399\n",
      "nDCG = 0.1191478225635397\n"
     ]
    }
   ],
   "source": [
    "mae = get_mae(predictions)\n",
    "rmse = get_rmse(predictions)\n",
    "precision = get_precision(predictions)\n",
    "recall = get_recall(predictions)\n",
    "f1 = get_f1(predictions)\n",
    "ndcg = get_ndcg(predictions)\n",
    "print(\"MAE = \" + str(mae))\n",
    "print(\"RMSE = \" + str(rmse))\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))\n",
    "print(\"F1 = \" + str(f1))\n",
    "print(\"nDCG = \" + str(ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCLMvQKmKrQ5"
   },
   "source": [
    "## Añadiendo los bias\n",
    "\n",
    "El modelo descrito anteriormente mejora significativamente la escalabilidad del filtrado colaborativo y, además, incremente notablemente la calidad de las predicciones y recomendaciones. Sin embargo, dicho modelo no se ajusta a la realidad puesto que no refleja los sesgos que los usuarios tienen cuando realizan votaciones.\n",
    "\n",
    "Parece evidente pensar que no todos los usuarios tienen la misma interpretación de las votaciones. Por ejemplo, existen usuarios más \"generosos\" con las votaciones que tienden a asignar siempre valoraciones altas y existen usuarios más \"tacaños\" con las votaciones que tienden a asignar siempre valoraciones más bajas. Que el primer usuario valore un item con 5 y el segundo usuario valore el mismo item con un 4 no quiere decir que al primero le haya gustado más el item. Cada usuario hace su propia interpretación de lo que significan los votos 4 y 5.\n",
    "\n",
    "Igualmente, existen determinados items que socialmente tienen que gustar y existen otros items que está \"mal visto\" que gusten. Por ejemplo, resulta extraño que alguien pueda otorgar la nota mínima a *El Padrino* aunque no le haya gustado. La presión social hace que dicha película sea importante, y eso condiciona nuestro voto sobre la misma. Igualmente, resulta extraño que alguien pueda otorgar la nota máxima a *Sharknado* ya que, socialmente, es considerada una película \"mala\".\n",
    "\n",
    "Para reflejar este fenómeno dentro de nuestro modelo de factorización matricial, debemos hacer algunas modificaciones sobre el mismo. Para empezar, cambiaremos cómo se calculan las predicciones:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\mu + b_u + b_i + \\vec{p}_u \\cdot \\vec{q}_i$$\n",
    "\n",
    "Donde $\\mu$ representa la votación media de la base de datos, $b_u$ representa el bias (sesgo) del usuario $u$, $b_i$ representa el bias (sesgo) del item $i$ y $\\vec{p}_u \\cdot \\vec{q}_i$ simboliza la interacción entre el usuario $u$ y el item $i$.\n",
    "\n",
    "De este modo, la predicción será calculada como la media de la base de datos, +/- un ajuste en función de cómo suele votar el usuario, +/- un ajuste de cómo suele votarse el item, y +/- la interacción entre el usuario y el item.\n",
    "\n",
    "Debido a este cambio, la función a minimizar es ahora la siguiente:\n",
    "\n",
    "$$\\min_{b_u, b_i,p,q} \\sum_{(u,i) \\in R} ( r_{u,i} - \\mu - b_u - b_i - \\vec{p}_u \\cdot \\vec{q}_i)^2 + \\lambda (||\\vec{p}_u||^2 + ||\\vec{q}_i||^2 + b_u^2 + b_i^2)$$\n",
    "\n",
    "Y ahora toca calcular la derivada respecto de $b_u$, $b_i$, $\\vec{p}_u$ y $\\vec{q}_i$ para poder aplicar el descenso por gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjjXM5XMPqHv"
   },
   "source": [
    "Definimos una nueva función para calcular las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biased_prediction(avg, b_u, b_i, p_u, q_i):\n",
    "    deviation = 0\n",
    "    for k in range(NUM_FACTORS):\n",
    "        deviation += p_u[k] * q_i[k]\n",
    "\n",
    "    prediction = avg + b_u + b_i + deviation\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1NUpz4-P-Yd"
   },
   "source": [
    "Calculamos el voto medio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "-tyed6WXQAC3"
   },
   "outputs": [],
   "source": [
    "rating_average = 0\n",
    "rating_count = 0\n",
    "\n",
    "for u in range(NUM_USERS):\n",
    "  for i in range(NUM_ITEMS):\n",
    "    if ratings[u][i] != None:\n",
    "      rating_average += ratings[u][i]\n",
    "      rating_count += 1\n",
    "\n",
    "rating_average /= rating_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a9_dMy_QVQ2"
   },
   "source": [
    "Reiniciamos las matrices de factores y los vectores de bias con valores aleatorios en el intervalo \\[0, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "qMnjONUwQbH0"
   },
   "outputs": [],
   "source": [
    "p = [[random.random() for _ in range(NUM_FACTORS)] for _ in range(NUM_USERS)]\n",
    "q = [[random.random() for _ in range(NUM_FACTORS)] for _ in range(NUM_ITEMS)]\n",
    "\n",
    "bu = [random.random() for _ in range(NUM_USERS)]\n",
    "bi = [random.random() for _ in range(NUM_ITEMS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_np = np.array(p) # np.random.random((NUM_USERS, NUM_FACTORS))\n",
    "q_np = np.array(q) # np.random.random((NUM_ITEMS, NUM_FACTORS))\n",
    "bu_np = np.array(bu) # np.random.random(NUM_USERS)\n",
    "bi_np = np.array(bi) # np.random.random(NUM_ITEMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGF76kqiStDb"
   },
   "source": [
    "Y volvemos a entrenar nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:18,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 2 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:16,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 3 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 5 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 6 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 7 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 8 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 9 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:18<00:02,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 10 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "for it in tqdm(range(NUM_ITERATIONS)):\n",
    "    print(\"Iteración \" + str(it + 1) + \" de \" + str(NUM_ITERATIONS))\n",
    "\n",
    "    updated_p = list(p) # clone p matrix\n",
    "    updated_q = list(q) # clone q matrix\n",
    "\n",
    "    updated_bu = list(bu) # clone bu vector\n",
    "    updated_bi = list(bi) # clone bi vector\n",
    "\n",
    "    for u in range(NUM_USERS):\n",
    "        for i in range(NUM_ITEMS):\n",
    "            if ratings[u][i] != None:\n",
    "\n",
    "                prediction = compute_biased_prediction(rating_average, bu[u], bi[i], p[u], q[i])\n",
    "                rating = ratings[u][i]\n",
    "                error = rating - prediction\n",
    "\n",
    "                for k in range(NUM_FACTORS):\n",
    "                    updated_p[u][k] += LEARNING_RATE * (error * q[i][k] - REGULARIZATION * p[u][k])\n",
    "                    updated_q[i][k] += LEARNING_RATE * (error * p[u][k] - REGULARIZATION * q[i][k])\n",
    "\n",
    "                updated_bu[u] += LEARNING_RATE * (error - REGULARIZATION * bu[u])\n",
    "                updated_bi[i] += LEARNING_RATE * (error - REGULARIZATION * bi[i])\n",
    "\n",
    "\n",
    "    p = updated_p\n",
    "    q = updated_q\n",
    "\n",
    "    bu = updated_bu\n",
    "    bi = updated_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.30501727, -0.54552793,  0.72193678, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 0.27583127,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       ...,\n",
       "       [ 0.53390796,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,  1.68065595,         nan, ...,         nan,\n",
       "                nan,         nan]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:03,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 2 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:03,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 3 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:01<00:02,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 5 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:02<00:02,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 6 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:02<00:01,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 7 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:03<00:01,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 8 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:03<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 9 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:04<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 10 de 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "ratings = np.asarray(ratings)\n",
    "valids = ~np.isnan(ratings_np)\n",
    "full_shape = *ratings_np.shape, NUM_FACTORS\n",
    "for it in tqdm(range(NUM_ITERATIONS)):\n",
    "    print(\"Iteración \" + str(it + 1) + \" de \" + str(NUM_ITERATIONS))\n",
    "    \n",
    "    predictions = rating_average + bu_np[:,np.newaxis] + (p_np @ q_np.T) + bi_np\n",
    "    errors = ratings_np - predictions\n",
    "    p_np += LEARNING_RATE * (np.broadcast_to(errors[..., np.newaxis], full_shape) * q_np - REGULARIZATION * p_np[:, np.newaxis, :]).sum(axis=1, where=valids[..., np.newaxis])\n",
    "    q_np += LEARNING_RATE * (np.broadcast_to(errors[..., np.newaxis], full_shape) * p_np[:, np.newaxis, :] - REGULARIZATION * q_np[np.newaxis, ...]).sum(axis=0, where=valids[..., np.newaxis])\n",
    "    bu_np += LEARNING_RATE * (errors - REGULARIZATION * bu_np[:,np.newaxis]).sum(axis=1, where=valids)\n",
    "    bi_np += LEARNING_RATE * (errors - REGULARIZATION * bi_np).sum(axis=0, where=valids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNE4FHibCXEt"
   },
   "source": [
    "##Ejercicio: Cálculo de Métricas\n",
    "\n",
    "Calcular el error medio absoluto (MAE) y la raiz del error medio cuadrático (RMSE) de las predicciones realizadas por el algoritmo PMF con bias, así como la precisión, recall, F1 y nDCG de las recomendaciones.\n",
    "\n",
    "Para ello, lo primero que debemos hacer es calcular las predicciones para todos los items que haya recibido una votación de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "S_WodJyQVkXV"
   },
   "outputs": [],
   "source": [
    "predictions = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)]\n",
    "\n",
    "for u in range(NUM_USERS):\n",
    "  for i in range(NUM_ITEMS):\n",
    "    if test_ratings[u][i] != None:\n",
    "      predictions[u][i] = compute_biased_prediction(rating_average, bu[u], bi[i], p[u], q[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "o0_R9o-ICpS6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.950195917559441\n",
      "RMSE = 1.1737241676230359\n",
      "Precision = 0.6268376068376066\n",
      "Recall = 0.5101915280841663\n",
      "F1 = 0.49349485223986633\n",
      "nDCG = 0.10929076005974227\n"
     ]
    }
   ],
   "source": [
    "mae = get_mae(predictions)\n",
    "rmse = get_rmse(predictions)\n",
    "precision = get_precision(predictions)\n",
    "recall = get_recall(predictions)\n",
    "f1 = get_f1(predictions)\n",
    "ndcg = get_ndcg(predictions)\n",
    "print(\"MAE = \" + str(mae))\n",
    "print(\"RMSE = \" + str(rmse))\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))\n",
    "print(\"F1 = \" + str(f1))\n",
    "print(\"nDCG = \" + str(ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (rating_average + bu_np[:,np.newaxis] + (p_np @ q_np.T) + bi_np).astype(object)\n",
    "predictions[np.isnan(test_ratings_np)] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.9524264131613294\n",
      "RMSE = 1.1749433677271972\n",
      "Precision = 0.6258119658119654\n",
      "Recall = 0.5070066751201013\n",
      "F1 = 0.4912390179763843\n",
      "nDCG = 0.1092170092234227\n"
     ]
    }
   ],
   "source": [
    "mae = get_mae(predictions)\n",
    "rmse = get_rmse(predictions)\n",
    "precision = get_precision(predictions)\n",
    "recall = get_recall(predictions)\n",
    "f1 = get_f1(predictions)\n",
    "ndcg = get_ndcg(predictions)\n",
    "print(\"MAE = \" + str(mae))\n",
    "print(\"RMSE = \" + str(rmse))\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))\n",
    "print(\"F1 = \" + str(f1))\n",
    "print(\"nDCG = \" + str(ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yWizA0nWvg1"
   },
   "source": [
    "## Referencias\n",
    "\n",
    "Mnih, A., & Salakhutdinov, R. R. (2008). **Probabilistic matrix factorization**. In Advances in neural information processing systems (pp. 1257-1264).\n",
    "\n",
    "Koren, Y., Bell, R., & Volinsky, C. (2009). **Matrix factorization techniques for recommender systems**. Computer, (8), 30-37."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
