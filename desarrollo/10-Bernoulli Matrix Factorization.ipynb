{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjPUbFbgwPhR"
   },
   "source": [
    "# Bernoulli Matrix Factorization\n",
    "\n",
    "En líneas generales, los algoritmos de factorización matricial vistos hasta el momento funcionan de forma correcta en la mayoría de los casos. Sin embargo, estos algoritmos están fundamentados matemáticamente en un supuesto erróneo: las votaciones en un sistema de recomendación son discretas y no continuas. Dicho de otro modo, PMF asume que la distribución que subyace a los votos es gaussiana y, por tanto, se permite cualquier valor de votación (por ejemplo, 3.4) a pesar de que las votaciones habitualmente están restringidas (por ejemplo, 1, 2, 3, 4 ó 5).\n",
    "\n",
    "Para solventar este problema, Bernoulli Matrix Factorization (BeMF) plantea utilizar una distribución de probabilidad discreta, la distribución de Bernoulli, para representar los votos. La distribución de Bernoulli requiere que los datos de entrada sean binarios (0 ó 1, verdadero o falso), por lo que, para adaptarla al problema del filtrado colaborativo, se requiere pre-procesar la matriz de votos.\n",
    "\n",
    "La siguiente figura resume el funcionamiento de BeMF. El *dataset* de entrada es dividido en tantas matrices (dispersas) como posibles votaciones (*scores*) haya (en el caso de la imagen 5 matrices). Cada una de esas matrices contiene una representación binaria del voto, teniendo el valor 0 si el usuario no voto el ítem con la puntación del *score* y 1 en caso contrario. Posteriormente, se aplica un proceso de factorización matricial a cada una de estas matrices asumiendo que los votos siguen una distribución de Bernoulli. Finalmente, los resultados son combinados para obtener la predicción del algoritmo, que será la que obtenga la puntuación (estimación) más alta.\n",
    "\n",
    "<img src=https://i.ibb.co/58f4n0P/Be-MF-architecture.png style='background-color: white'>\n",
    "\n",
    "Una gran ventaja de este algoritmo, más allá de su robustez matemática, es que no proporciona únicamente predicciones, si no que indica, además, la fiabilidad de estas predicciones. Esto permite modular la salida del modelo para proporcionar no solo predicciones altas si no también fiables. ¿Es mejor una predicción de 5 con una fiabilidad de 0,5 o una predicción de 4 con una fiabilidad de 0,9?\n",
    "\n",
    "Entendido el algoritmo, debemos determinar cómo calculamos las factorizaciones de Bernoulli para cada *score*. Para ello fijamos $s \\in \\mathcal{S}$ como posibles votaciones. Para aliviar la notación llamaremos $R = R^s$ a la matriz de votaciones del *score* $s$.\n",
    "\n",
    "Definimos una función logística $\\psi: \\mathbb{R} \\to [0,1]$ monótona creciente que cumpla $\\psi(x) \\to 0$ cuando    $x \\to -\\infty$ y $\\psi(x) \\to 1$ cuando $x \\to \\infty$.\n",
    "\n",
    "Dado el usuario $u$ y el ítem $i$ se asume que sus votaciones $R_{u,i}$ siguen una distribución de Bernoulli con una probabilidad de éxito $\\psi(U_u \\cdot V_i)$, siendo usuario $U_u$ y $V_i$ la representación latente del usuario $u$ y el ítem $i$ en vectores de dimensión $k>0$.\n",
    "\n",
    "La función de masa de esta variable aleatoria $p(R_{u,i} | U_u, V_i)$ viene dada por:\n",
    "\n",
    "$$\n",
    "        p(R_{u,i} | U_u, V_i) = \\left\\{\\begin{matrix}\\psi(U_uV_i) & \\textrm{if } R_{u,i} = 1, \\\\ 1-\\psi(U_uV_i) & \\textrm{if } R_{u,i} = 0.\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "De esta fórmula podemos obtener la función de verosimilitud:\n",
    "\n",
    "$$\n",
    "L(R | U, V) = \\prod_{R_{u,i} \\neq \\bullet} p(R_{u,i} | U_u, V_i) = \\left(\\prod_{R_{u,i} = 1} \\psi(U_uV_i)\\right)\\left(\\prod_{R_{u,i} = 0} 1-\\psi(U_uV_i)\\right).\n",
    "$$\n",
    "\n",
    "Y el la log-verosimilitud $l(R | U, V) = \\log L(R | U, V)$:\n",
    "\n",
    "$$\n",
    "l(R | U, V) =    \\sum_{R_{u,i} = 1} \\log(\\psi(U_uV_i)) + \\sum_{R_{u,i} = 0} \\log(1-\\psi(U_uV_i)).\n",
    "$$\n",
    "\n",
    "Dada esta función, y asumiendo las distribuciones a priori $U$ y $V$ como gaussianas de media 0 y desviaciones típicas $\\sigma_U, \\sigma_V > 0$, sus funciones de densidad son:\n",
    "\n",
    "$$\n",
    "        p(U_u) = \\frac{1}{\\sigma_U \\sqrt{2\\pi}} \\exp\\left(-\\frac{||U_u||^2}{2\\sigma_U^2}\\right), \\quad p(V_i) = \\frac{1}{\\sigma_V \\sqrt{2\\pi}} \\exp\\left(-\\frac{||V_i||^2}{2\\sigma_V^2}\\right).\n",
    "$$\n",
    "\n",
    "Y las de verosimilitud:\n",
    "\n",
    "$$\n",
    "        L(U) = \\prod_{u=1}^N p(U_u) = \\frac{1}{\\sigma_U^N (2\\pi)^{N/2}} \\prod_{u=1}^N \\exp\\left(-\\frac{||U_u||^2}{2\\sigma^2_U}\\right) = \\frac{1}{\\sigma_U^N (2\\pi)^{N/2}}    \\exp\\left(-\\frac{\\sum_{u=1}^N ||U_u||^2}{2\\sigma^2_U}\\right),\n",
    "$$\n",
    "$$\n",
    "        L(V) = \\prod_{i=1}^M p(V_i) = \\frac{1}{\\sigma^M_V (2\\pi)^{M/2}} \\prod_{i=1}^M \\exp\\left(-\\frac{||V_i||^2}{2\\sigma_V^2}\\right) = \\frac{1}{\\sigma_V^M (2\\pi)^{M/2}}    \\exp\\left(-\\frac{\\sum_{i=1}^M ||V_i||^2}{2\\sigma_V^2}\\right).\n",
    "$$\n",
    "\n",
    "Y las de log-verosimilitud:\n",
    "\n",
    "$$\n",
    "        l(U) = -\\frac{1}{2\\sigma_U^2}\\sum_{u=1}^N ||U_u||^2 + C_U, \\quad\n",
    "        l(V) = -\\frac{1}{2\\sigma_V^2}\\sum_{i=1}^M ||V_i||^2 + C_V.\n",
    "$$\n",
    "\n",
    "para las constantes $C_U = -N\\log(\\sigma_U \\sqrt{2\\pi})$ y $C_V = -M\\log(\\sigma_V \\sqrt{2\\pi})$.\n",
    "\n",
    "Finalmente, la función de verosimilitud a posteriori, $L(R)$, es\n",
    "\n",
    "$$\n",
    "        L(R) = L(R | U, V) L(U) L(V).\n",
    "$$\n",
    "\n",
    "Y la log-verosimilitud es\n",
    "\n",
    "\\begin{align*}\n",
    "l(R) &= l(R |U,V) + l(U) + l(V) \\\\\n",
    "&= \\sum_{R_{u,i} = 1} \\log(\\psi(U_uV_i)) + \\sum_{R_{u,i} = 0} \\log(1-\\psi(U_uV_i)) \\\\ &\\hspace{0.5cm}-\\frac{1}{2\\sigma_U^2}\\sum_{u=1}^N ||U_u||^2 -\\frac{1}{2\\sigma_V^2}\\sum_{i=1}^M ||V_i||^2 + C,\n",
    "\\end{align*}\n",
    "\n",
    "donde $C = C_U + C_V$ es una constante\n",
    "\n",
    "El **estimador de máxima verosimilitud** se obtiene maximizando esta log-verosimilitud a posteriori. Para este propósito, la constante $C$ es irrelevante y puede ser omitida. Fijando $\\eta_U = \\frac{1}{\\sigma_U^2}$ y $\\eta_V = \\frac{1}{\\sigma_V^2}$, el problema de maximización puede ser convertido a minimizar la función de coste\n",
    "\n",
    "$$\n",
    "F(U, V) = -\\sum_{R_{u,i} = 1} \\log(\\psi(U_uV_i)) - \\sum_{R_{u,i} = 0} \\log(1-\\psi(U_uV_i)) + \\frac{\\eta_U}{2}\\sum_{u=1}^N ||U_u||^2 + \\frac{\\eta_V}{2}\\sum_{i=1}^M ||V_i||^2.\n",
    "$$\n",
    "\n",
    "Para optimizar esta función de coste usaremos **descenso de gradiente**. Fijado el usuario $u_0$ y el ítem $i_0$, denotando sus factores latente $U_{u_0} = (U_{u_0, 1}, \\ldots, U_{u_0, k})$ y $V_{i_0} = (V_{i_0, 1}, \\ldots, V_{i_0, k})$. Las derivadas parciales de $F$ con respecto a $U_{u_0, a}$ y $V_{i_0, b}$ vienen dadas por\n",
    "\n",
    "$$\n",
    "        \\frac{\\partial F}{\\partial U_{u_0,a}} = -\\sum_{\\left\\{i \\,|\\, R_{u_0,i} = 1\\right\\}} \\frac{\\psi'(U_{u_0}V_i)}{\\psi(U_{u_0}V_i)}V_{i,a} + \\sum_{\\left\\{i \\,|\\, R_{u_0,i} = 0\\right\\}} \\frac{\\psi'(U_{u_0}V_i)}{1-\\psi(U_{u_0}V_i)}V_{i,a} + \\eta_U U_{u_0,a},\n",
    "$$\n",
    "$$\n",
    "        \\frac{\\partial F}{\\partial V_{i_0,b}} = -\\sum_{\\left\\{u \\,|\\, R_{u,i_0} = 1\\right\\}} \\frac{\\psi'(U_{u}V_{i_0})}{\\psi(U_{u}V_{i_0})}U_{u,b} + \\sum_{\\left\\{u \\,|\\, R_{u,i_0} = 0\\right\\}} \\frac{\\psi'(U_{u}V_{i_0})}{1-\\psi(U_{u}V_{i_0})}U_{u,b} + \\eta_V V_{i_0,b}.\n",
    "$$\n",
    "\n",
    "Por simplificar, tomamos $\\eta_U = \\eta_V = \\eta$. Los pasos del descenso de gradiente de paso $\\gamma > 0$ para la iteración $T+1$ son\n",
    "\n",
    "$$\n",
    "        U_u^{T+1} = U_u^{T} + \\gamma \\left(\\sum_{\\left\\{i \\,|\\, R_{u,i} = 1\\right\\}} \\frac{\\psi'(U_{u}V_i)}{\\psi(U_{u}V_i)}V_{i} - \\sum_{\\left\\{i \\,|\\, R_{u,i} = 0\\right\\}} \\frac{\\psi'(U_{u}V_i)}{1-\\psi(U_{u}V_i)}V_{i} - \\eta U_{u}\\right),\n",
    "$$\n",
    "$$\n",
    "        V_i^{T+1} = V_i^{T} + \\gamma \\left(\\sum_{\\left\\{u \\,|\\, R_{u,i} = 1\\right\\}} \\frac{\\psi'(U_{u}V_{i})}{\\psi(U_{u}V_{i})}U_{u} - \\sum_{\\left\\{u \\,|\\, R_{u,i} = 0\\right\\}} \\frac{\\psi'(U_{u}V_{i})}{1-\\psi(U_{u}V_{i})}U_{u} - \\eta V_{i}\\right).\n",
    "$$\n",
    "\n",
    "Si usamos como función logística $\\psi(x) = logit(x) = \\frac{1}{1+e^{-x}}$, donde $logit'(x) = logit(x) (1-logit(x))$, entonces las ecuaciones de actualización se simplifican como\n",
    "\n",
    "$$\n",
    "        U_u^{T+1} = U_u^{T} + \\gamma \\left(\\sum_{\\left\\{i \\,|\\, R_{u,i} = 1\\right\\}} (1-\\mathrm{logit}(U_{u}V_i))V_{i} - \\sum_{\\left\\{i \\,|\\, R_{u,i} = 0\\right\\}} \\mathrm{logit}(U_{u}V_i)V_{i} - \\eta U_{u}\\right),\n",
    "$$\n",
    "$$\n",
    "        V_i^{T+1} = V_i^{T} + \\gamma \\left(\\sum_{\\left\\{u \\,|\\, R_{u,i} = 1\\right\\}} (1-\\mathrm{logit}(U_{u}V_i))U_{u} - \\sum_{\\left\\{u \\,|\\, R_{u,i} = 0\\right\\}} \\mathrm{logit}(U_{u}V_i)U_{u} - \\eta V_{i}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj19DL6RCIZq"
   },
   "source": [
    "## Carga del dataset\n",
    "\n",
    "Para ilustar mejor el funcionamiento el algoritmo BeMF, vamos a desarrollar una implementación del mismo.\n",
    "\n",
    "Para ello usaremos el dataset de [MovieLens 100K](https://grouplens.org/datasets/movielens/) que contiene 100.000 votos de 943 usuarios sobre 1682 películas. Este dataset ha sido dividido en votaciones de entrenamiento (80%) y votaciones de test (20%). Además, los códigos de usuarios e items han sido modificados para que comience en 0 y terminen en el número de (usuarios / items) - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Y1rRJ8hCi2A"
   },
   "source": [
    "Inicialmente definimos algunas constantes que nos serán necesarias durante la codificación del algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j-n03OB1CxVe"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "f6WGa59gwPhS"
   },
   "outputs": [],
   "source": [
    "NUM_USERS = 943\n",
    "NUM_ITEMS = 1682\n",
    "\n",
    "MIN_RATING = 1\n",
    "MAX_RATING = 5\n",
    "\n",
    "SCORES = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYYRgNNZtGpE"
   },
   "source": [
    "Y cargamos la matriz con las votaciones de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aGtDGaQEwPhW"
   },
   "outputs": [],
   "source": [
    "ratings = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)]\n",
    "\n",
    "training_file = urllib.request.urlopen(\"https://drive.upm.es/s/tDdluElfGInyUnU/download\")\n",
    "for line in training_file:\n",
    "    [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n",
    "    ratings[int(u)][int(i)] = int(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_np = np.array(ratings)\n",
    "ratings_np[ratings_np == None] = np.nan\n",
    "ratings_np = ratings_np.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynbsIDxnC2OI"
   },
   "source": [
    "Del mismo modo, cargamos la matriz de votaciones de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qJ4y0dY8C5GB"
   },
   "outputs": [],
   "source": [
    "test_ratings = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)]\n",
    "\n",
    "test_file = urllib.request.urlopen(\"https://drive.upm.es/s/Jn75Vg6okOPsgZu/download\")\n",
    "for line in test_file:\n",
    "    [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n",
    "    test_ratings[int(u)][int(i)] = int(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings_np = np.array(test_ratings)\n",
    "test_ratings_np[test_ratings_np == None] = np.nan\n",
    "test_ratings_np = test_ratings_np.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJ_HI4_pwPhZ"
   },
   "source": [
    "## Inicialización del modelo\n",
    "\n",
    "Definimos los parámetros necesarios para implementar la factorización matricial mediante BeMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OLkqFAFgwPha"
   },
   "outputs": [],
   "source": [
    "NUM_FACTORS = 7\n",
    "LEARNING_RATE = 0.001\n",
    "REGULARIZATION = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6LFYsvgwPhd"
   },
   "source": [
    "Inicializamos las matrices de factores con valores uniformes aleatorios en el intervalo \\[0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GiMfSEhZwPhe"
   },
   "outputs": [],
   "source": [
    "U = [[[random.random() for _ in range(NUM_FACTORS)] for _ in range(NUM_USERS)] for _ in range(len(SCORES))]\n",
    "V = [[[random.random() for _ in range(NUM_FACTORS)] for _ in range(NUM_ITEMS)] for _ in range(len(SCORES))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_np = np.array(U) # np.random.rand(len(SCORES), NUM_USERS, NUM_FACTORS)\n",
    "V_np = np.array(V) # np.random.rand(len(SCORES), NUM_ITEMS, NUM_FACTORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCTcKsnewPhg"
   },
   "source": [
    "## Cálculo de las predicciones\n",
    "\n",
    "A diferencia de otros modelos de factorización matricial, el cálculo de las predicciones implica encontrar la puntuación $s$ en la que se maximiza la probabilidad del voto:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,i} = arg \\max_{s} \\psi(U_u^s \\cdot V_i^s)\n",
    "$$\n",
    "\n",
    "La siguiente función realiza esta operación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HC1FxBMQDA4l"
   },
   "outputs": [],
   "source": [
    "def logit (x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_np(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vSJqb_UqwPhh"
   },
   "outputs": [],
   "source": [
    "def compute_prediction(u, i):\n",
    "    prediction = None\n",
    "    prob = 0\n",
    "    for s in range(len(SCORES)):\n",
    "        dot = np.dot(U[s][u], V[s][i])\n",
    "        if logit(dot) > prob:\n",
    "            prob = logit(dot)\n",
    "            prediction = SCORES[s]\n",
    "    return prediction, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQAGR9VWHCVe"
   },
   "source": [
    "## Aprendizaje de los factores latentes\n",
    "\n",
    "El proceso de entrenamiento implicar aplicar las operaciones de actualización de las matrices de factores hasta que el algoritmo converja. En general, esta convergencia suele prefijarse como el número de iteraciones que realizamos sobre las operaciones de actualización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "XSqfmucPHY0g"
   },
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCNTid22HbDN"
   },
   "source": [
    "El siguiente código ejemplifica el proceso de entrenamiento del algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5:18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LfIi2j9wPhm"
   },
   "outputs": [],
   "source": [
    "for it in range(NUM_ITERATIONS):\n",
    "    print(\"Iteración \" + str(it + 1) + \" de \" + str(NUM_ITERATIONS))\n",
    "\n",
    "    for s in range(len(SCORES)):\n",
    "\n",
    "        # Update users\n",
    "        for u in range(NUM_USERS):\n",
    "            delta = np.zeros(NUM_FACTORS)\n",
    "            for i in range(NUM_ITEMS):\n",
    "                dot = np.dot(U[s][u], V[s][i])\n",
    "                for f in range(NUM_FACTORS):\n",
    "                    if ratings[u][i] == SCORES[s]:\n",
    "                        delta[f] += (1 - logit(dot)) * V[s][i][f]\n",
    "                    else:\n",
    "                        delta[f] -= logit(dot) * V[s][i][f]\n",
    "\n",
    "            delta -= REGULARIZATION * np.asarray(U[s][u])\n",
    "            delta *= LEARNING_RATE\n",
    "            U[s][u] += delta\n",
    "\n",
    "\n",
    "        for i in range(NUM_ITEMS):\n",
    "            delta = np.zeros(NUM_FACTORS)\n",
    "            for u in range(NUM_USERS):\n",
    "                dot = np.dot(U[s][u], V[s][i])\n",
    "                for f in range(NUM_FACTORS):\n",
    "                    if ratings[u][i] == SCORES[s]:\n",
    "                        delta[f] += (1 - logit(dot)) * U[s][u][f]\n",
    "                    else:\n",
    "                        delta[f] -= logit(dot) * U[s][u][f]\n",
    "            \n",
    "            delta -= REGULARIZATION * np.asarray(V[s][i])\n",
    "            delta *= LEARNING_RATE\n",
    "            V[s][i] += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1 de 10\n",
      "Iteración 2 de 10\n",
      "Iteración 3 de 10\n",
      "Iteración 4 de 10\n",
      "Iteración 5 de 10\n",
      "Iteración 6 de 10\n",
      "Iteración 7 de 10\n",
      "Iteración 8 de 10\n",
      "Iteración 9 de 10\n",
      "Iteración 10 de 10\n"
     ]
    }
   ],
   "source": [
    "# Hay un problema con la vectorización\n",
    "# Esto es que los factores sufren \"RAW\" y \"WAR\"\n",
    "# Por tanto no se puede vectorizar totalmente sin perder el funcionamiento \n",
    "# intencionado que es que vaya dando pasos por cada usuario y cada item en vez \n",
    "# de dar un paso global para usuarios y otro para items\n",
    "\n",
    "for it in range(NUM_ITERATIONS):\n",
    "    print(\"Iteración \" + str(it + 1) + \" de \" + str(NUM_ITERATIONS))\n",
    "\n",
    "    for s in range(len(SCORES)):\n",
    "\n",
    "        # Update users\n",
    "        for u in range(NUM_USERS):\n",
    "            dots = V_np[s] @ U_np[s][u].T\n",
    "            dots_logit = logit_np(dots)\n",
    "            positive = ratings_np[u] == SCORES[s]\n",
    "            delta = ((positive * (1 - dots_logit))[:, np.newaxis] * V_np[s] - ((1 - positive) * dots_logit)[:, np.newaxis] * V_np[s]).sum(axis=0)\n",
    "            delta -= REGULARIZATION * U_np[s][u]\n",
    "            delta *= LEARNING_RATE\n",
    "            U[s][u] += delta\n",
    "\n",
    "        # Update items\n",
    "        for i in range(NUM_ITEMS):\n",
    "            dots = U_np[s] @ V_np[s][i].T\n",
    "            dots_logit = logit_np(dots)\n",
    "            positive = ratings_np[:,i] == SCORES[s]\n",
    "            delta = ((positive * (1 - dots_logit))[:, np.newaxis] * U_np[s] - ((1 - positive) * dots_logit)[:, np.newaxis] * U_np[s]).sum(axis=0)\n",
    "            delta -= REGULARIZATION * V_np[s][i]\n",
    "            delta *= LEARNING_RATE\n",
    "            V[s][i] += delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nDssq0bIPJJ"
   },
   "source": [
    "## Cálculo de las recomendaciones\n",
    "\n",
    "El cálculo de las recomendaciones, por lo general, simplemente implica seleccionar los *N* items con una predicción más alta. Por ejemplo, si quisiéramos recomendar *N = 3* items a un usuario que tuviera las siguientes predicciones:\n",
    "\n",
    "|     \t| i1 \t| i2 \t| i3 \t| i4 \t| i5 \t| i6 \t| i7 \t| i8 \t| i9 \t| i10 \t|\n",
    "|:-:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|-----\t|\n",
    "| u \t|     \t|    2,9 \t|        \t|    4,7 \t|    5,0 \t|        \t|    1,2 \t|        \t|     \t|    3,1 \t|\n",
    "\n",
    "Se le recomendarían a dicho usuario los items *i5*, *i4* e *i10*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "u-0i0xSrkcXX"
   },
   "outputs": [],
   "source": [
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "AHnvC0Dbj7_N"
   },
   "outputs": [],
   "source": [
    "def get_recommendations (predictions):\n",
    "    recommendations = [None for _ in range(N)]\n",
    "\n",
    "    for n in range(N):\n",
    "\n",
    "        max_value = 0\n",
    "        item = None\n",
    "\n",
    "        for i, value in enumerate(predictions):\n",
    "            if i not in recommendations and value != None and value > max_value:\n",
    "                max_value = value\n",
    "                item = i\n",
    "        recommendations[n] = item\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt2nzde9IzES"
   },
   "source": [
    "##Ejercicio: Cálculo de Métricas\n",
    "\n",
    "Calcular el error medio absoluto (MAE) y la raiz del error medio cuadrático (RMSE) de las predicciones realizadas por el algoritmo BeMF, así como la precisión, recall, F1 y nDCG de las recomendaciones.\n",
    "\n",
    "Para ello, lo primero que debemos hacer es calcular las predicciones para todos los items que haya recibido una votación de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "nU5wPGD_JD_L"
   },
   "outputs": [],
   "source": [
    "predictions = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)]\n",
    "\n",
    "# Rellenamos la matriz de predicciones\n",
    "for u in range(NUM_USERS):\n",
    "    for i in range(NUM_ITEMS):\n",
    "        if test_ratings[u][i] != None:\n",
    "            pred, prob = compute_prediction(u, i)\n",
    "            predictions[u][i] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction(u, i):\n",
    "    prediction = None\n",
    "    prob = 0\n",
    "    for s in range(len(SCORES)):\n",
    "        dot = np.dot(U[s][u], V[s][i])\n",
    "        if logit(dot) > prob:\n",
    "            prob = logit(dot)\n",
    "            prediction = SCORES[s]\n",
    "    return prediction, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[None, None, None, ..., None, None, None],\n",
       "       [None, None, None, ..., None, None, None],\n",
       "       [None, None, None, ..., None, None, None],\n",
       "       ...,\n",
       "       [None, None, None, ..., None, None, None],\n",
       "       [None, None, None, ..., None, None, None],\n",
       "       [None, None, None, ..., None, None, None]], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute predictions\n",
    "logits = np.einsum('suf,sif->uis', U_np, V_np)\n",
    "probs = logit_np(logits)\n",
    "probs = probs / probs.sum(axis=-1)[..., np.newaxis] # Not needed, but interesting data\n",
    "predictions = SCORES[np.argmax(probs, axis=-1)].astype(object)\n",
    "predictions[np.isnan(test_ratings_np)] = None\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrRRzuNsJRIw"
   },
   "source": [
    "Y, a continuación, calculamos las métricas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_mae (u, predictions):\n",
    "  mae = 0\n",
    "  count = 0\n",
    "\n",
    "  for i in range(NUM_ITEMS):\n",
    "    if test_ratings[u][i] != None and predictions[u][i] != None:\n",
    "      mae += abs(test_ratings[u][i] - predictions[u][i])\n",
    "      count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return mae / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae (predictions):\n",
    "  mae = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_mae = get_user_mae(u, predictions)\n",
    "\n",
    "    if user_mae != None:\n",
    "      mae += user_mae\n",
    "      count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return mae / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_user_rmse (u, predictions):\n",
    "  mse = 0\n",
    "  count = 0\n",
    "\n",
    "  for i in range(NUM_ITEMS):\n",
    "    if test_ratings[u][i] != None and predictions[u][i] != None:\n",
    "      mse += (test_ratings[u][i] - predictions[u][i]) * (test_ratings[u][i] - predictions[u][i])\n",
    "      count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return math.sqrt(mse / count)\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse (predictions):\n",
    "  rmse = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_rmse = get_user_rmse(u, predictions)\n",
    "\n",
    "    if user_rmse != None:\n",
    "      rmse += user_rmse\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return rmse / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_precision (u, predictions):\n",
    "  precision = 0\n",
    "  count = 0\n",
    "  recommendations = get_recommendations(predictions[u])\n",
    "\n",
    "  for i in recommendations:\n",
    "    if i != None and test_ratings[u][i] != None:\n",
    "      precision += 1 if test_ratings[u][i] >= theta else 0\n",
    "      count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return precision / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision (predictions):\n",
    "  precision = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_precision = get_user_precision(u, predictions)\n",
    "\n",
    "    if user_precision != None:\n",
    "      precision += user_precision\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return precision / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recall (u, predictions):\n",
    "  recall = 0\n",
    "  count = 0\n",
    "  recommendations = get_recommendations(predictions[u])\n",
    "\n",
    "  for i in range(NUM_ITEMS):\n",
    "    if test_ratings[u][i] != None and predictions[u][i] != None:\n",
    "      if test_ratings[u][i] >= theta:\n",
    "        recall += 1 if i in recommendations else 0\n",
    "        count += 1\n",
    "\n",
    "  if count > 0:\n",
    "    return recall / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall (predictions):\n",
    "  recall = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_recall = get_user_recall(u, predictions)\n",
    "\n",
    "    if user_recall != None:\n",
    "      recall += user_recall\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return recall / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_f1 (u, predictions):\n",
    "  precision = get_user_precision(u, predictions)\n",
    "  recall = get_user_recall(u, predictions)\n",
    "\n",
    "  if precision == None or recall == None:\n",
    "    return None\n",
    "  elif precision == 0 and recall == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1 (predictions):\n",
    "  f1 = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_f1 = get_user_f1(u, predictions)\n",
    "\n",
    "    if user_f1 != None:\n",
    "      f1 += user_f1\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return f1 / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_test_items(u):\n",
    "  num_items = sum(x is not None for x in test_ratings[u])\n",
    "  items = [None for _ in range(num_items)]\n",
    "\n",
    "  for n in range(num_items):\n",
    "\n",
    "    max_value = 0\n",
    "    item = None\n",
    "\n",
    "    for i,value in enumerate(test_ratings[u]):\n",
    "      if i not in items and value != None and value > max_value:\n",
    "        max_value = value\n",
    "        item = i\n",
    "\n",
    "    items[n] = item\n",
    "\n",
    "  return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_idcg (u):\n",
    "  items = get_ordered_test_items(u)\n",
    "  idcg = 0\n",
    "\n",
    "  for pos, i in enumerate(items):\n",
    "    idcg += (2 ** test_ratings[u][i] - 1) / math.log(pos+2, 2)\n",
    "\n",
    "  return idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_dcg (u, recommendations):\n",
    "  dcg = 0\n",
    "\n",
    "  for pos, i in enumerate(recommendations):\n",
    "    if i != None and test_ratings[u][i] != None:\n",
    "      dcg += (2 ** test_ratings[u][i] - 1) / math.log(pos+2, 2)\n",
    "\n",
    "  return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ndcg (u, predictions):\n",
    "  recommendations = get_recommendations(predictions[u])\n",
    "  dcg = get_user_dcg(u, recommendations)\n",
    "  idcg = get_user_idcg(u)\n",
    "  if idcg == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg (predictions):\n",
    "  ndcg = 0\n",
    "  count = 0\n",
    "\n",
    "  for u in range(NUM_USERS):\n",
    "    user_ndcg = get_user_ndcg(u, predictions)\n",
    "\n",
    "    if user_ndcg != None:\n",
    "      ndcg += user_ndcg\n",
    "      count += 1\n",
    "\n",
    "\n",
    "  if count > 0:\n",
    "    return ndcg / count\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 1.5451816695559673\n",
      "RMSE = 1.869397693862923\n",
      "Precision = 0.5878632478632477\n",
      "Recall = 0.47579313695927167\n",
      "F1 = 0.45816952268787436\n",
      "nDCG = 0.10226429215421418\n"
     ]
    }
   ],
   "source": [
    "mae = get_mae(predictions)\n",
    "rmse = get_rmse(predictions)\n",
    "precision = get_precision(predictions)\n",
    "recall = get_recall(predictions)\n",
    "f1 = get_f1(predictions)\n",
    "ndcg = get_ndcg(predictions)\n",
    "print(\"MAE = \" + str(mae))\n",
    "print(\"RMSE = \" + str(rmse))\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))\n",
    "print(\"F1 = \" + str(f1))\n",
    "print(\"nDCG = \" + str(ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yWizA0nWvg1"
   },
   "source": [
    "## Referencias\n",
    "\n",
    "Ortega, F., Lara-Cabrera, R., González-Prieto, Á., & Bobadilla, J. (2021). **Providing reliability in recommender systems through Bernoulli Matrix Factorization**. Information Sciences, 553, 110-128.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1fLFKyhFqaB5RBxcvn0TntcShGokqBze-",
     "timestamp": 1646316681074
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
